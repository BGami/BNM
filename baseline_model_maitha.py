# -*- coding: utf-8 -*-
"""BaseLine_Model_Maitha.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KTm9hCZkIwcpu28pGuk3wuEDvYM0gmAn
"""

import numpy as np
from sklearn.model_selection import train_test_split


from google.colab import drive
drive.mount('/content/drive')

data = np.load("/content/drive/MyDrive/Colab Notebooks/drowsiness_features_updated_03.npz")
print(list(data.keys()))  # This will print all the keys in the npz file

import numpy as np


X = data['X_features']  # This may need adjustment based on the actual key used for features
y = data['Y_features']  # This may need adjustment based on the actual key used for labels

# Verify shapes
print(f'Features shape: {X.shape}')
print(f'Labels shape: {y.shape}')

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization
from tensorflow.keras.optimizers import Adam
model = Sequential([
    Flatten(input_shape=(1, 7, 7, 1280)),
    Dense(512, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(512, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])
optimizer = Adam(learning_rate=0.001)  # Adjusted learning rate
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))

from tensorflow.keras.models import load_model

# Assume 'model' is your trained model
model.save('/content/drive/MyDrive/Colab Notebooks/Baseline_model.h5')  # HDF5 file, you can specify a path here
print("Model saved successfully!")

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Evaluation part
y_pred_probs = model.predict(X_val)
y_pred = (y_pred_probs > 0.5).astype(int).flatten()

cm = confusion_matrix(y_val, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', xticklabels=['Non-Drowsy', 'Drowsy'], yticklabels=['Non-Drowsy', 'Drowsy'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()


# Classification Report
print("Classification Report:")
print(classification_report(y_val, y_pred, target_names=['Non-Drowsy', 'Drowsy']))