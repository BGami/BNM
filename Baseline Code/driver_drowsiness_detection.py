# -*- coding: utf-8 -*-
"""driver_drowsiness_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mNctVnWfCDIXYGRFH7zcD9hUoUQosCB6

# Driver Drowsiness Detection System

This notebook implements a comprehensive Driver Drowsiness Detection System using artificial intelligence and computer vision. The system detects early signs of driver fatigue, such as prolonged eye closure or yawning, using a CNN-based model.

## Setup and Imports
"""

# Install required packages
!pip install tensorflow opencv-python scikit-learn pillow matplotlib pandas tqdm seaborn

# Import libraries
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization
from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import cv2
import zipfile
import shutil
from google.colab import drive
import glob
from IPython.display import clear_output, display
import time

# Reduce TensorFlow verbosity
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow logging
tf.get_logger().setLevel('ERROR')  # Only show errors

"""## Mount Google Drive and Define Constants"""

# Mount Google Drive
drive.mount('/content/drive')

# Define constants
IMG_SIZE = 128
BATCH_SIZE = 32
EPOCHS = 20  # Reduced from 50 to 20 to speed up training
BASE_DIR = '/content/driver_drowsiness_detection'
DATA_DIR = os.path.join(BASE_DIR, 'data')
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')
FEATURES_DIR = os.path.join(DATA_DIR, 'features')
MODELS_DIR = os.path.join(BASE_DIR, 'models')
LOGS_DIR = os.path.join(BASE_DIR, 'logs')

# Google Drive paths - Update this to your specific path
DRIVE_DATA_DIR = "/content/drive/MyDrive/Colab Notebooks/AI Studio/Project/train"
DRIVE_OUTPUT_DIR = "/content/drive/MyDrive/driver_drowsiness_models"

# Create directories
os.makedirs(BASE_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TRAIN_DIR, exist_ok=True)
os.makedirs(PROCESSED_DIR, exist_ok=True)
os.makedirs(FEATURES_DIR, exist_ok=True)
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)
os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)

"""## Helper Functions"""

# Custom callback to reduce output frequency
class ReducedLoggingCallback(tf.keras.callbacks.Callback):
    def __init__(self, log_every=5):
        super(ReducedLoggingCallback, self).__init__()
        self.log_every = log_every

    def on_epoch_begin(self, epoch, logs=None):
        if epoch % self.log_every == 0:
            print(f"\nStarting epoch {epoch+1}/{self.params['epochs']}")

    def on_epoch_end(self, epoch, logs=None):
        if epoch % self.log_every == 0 or epoch == self.params['epochs'] - 1:
            print(f"Epoch {epoch+1}/{self.params['epochs']} - val_accuracy: {logs.get('val_accuracy', 0):.4f}")

# Function to clear output after a delay
def clear_after_delay(seconds=2):
    time.sleep(seconds)
    clear_output(wait=True)

"""## Step 1: Load Dataset from Google Drive"""

def load_dataset_from_drive():
    print("Loading dataset from Google Drive...")

    # Check if dataset exists in Drive
    if not os.path.exists(DRIVE_DATA_DIR):
        print(f"Warning: {DRIVE_DATA_DIR} does not exist in Google Drive")
        return False

    # List contents of the directory
    print(f"Contents of {DRIVE_DATA_DIR}:")
    try:
        files = os.listdir(DRIVE_DATA_DIR)
        for file in files[:10]:  # Show only first 10 files to avoid clutter
            print(f"  {file}")
        if len(files) > 10:
            print(f"  ... and {len(files) - 10} more files")
    except Exception as e:
        print(f"Error listing directory: {e}")
        return False

    # Check if dataset is already in the expected format with subdirectories
    categories = ['Closed', 'Open', 'no_yawn', 'yawn']
    subdirs_exist = False

    for category in categories:
        category_path = os.path.join(DRIVE_DATA_DIR, category)
        if os.path.exists(category_path) and os.path.isdir(category_path):
            subdirs_exist = True
            break

    if subdirs_exist:
        print("Dataset found in Google Drive with category subdirectories")

        # Copy dataset from Drive to local directory
        for category in categories:
            src_dir = os.path.join(DRIVE_DATA_DIR, category)
            dst_dir = os.path.join(TRAIN_DIR, category)

            if os.path.exists(src_dir) and os.path.isdir(src_dir):
                os.makedirs(dst_dir, exist_ok=True)
                print(f"Copying {category} images from Drive...")

                # Get all image files
                try:
                    image_files = glob.glob(os.path.join(src_dir, "*.jpg")) + \
                                 glob.glob(os.path.join(src_dir, "*.jpeg")) + \
                                 glob.glob(os.path.join(src_dir, "*.png"))

                    # Copy each file individually
                    for img_path in image_files:
                        img_name = os.path.basename(img_path)
                        dst_path = os.path.join(dst_dir, img_name)
                        shutil.copy(img_path, dst_path)
                except Exception as e:
                    print(f"Error copying files: {e}")

        # Check the number of files in each directory
        print("Dataset statistics:")
        for category in categories:
            category_path = os.path.join(TRAIN_DIR, category)
            if os.path.exists(category_path):
                files = [f for f in os.listdir(category_path) if f.endswith(('.jpg', '.jpeg', '.png'))]
                print(f"  {category}: {len(files)} images")

        return True
    else:
        print("Dataset in Google Drive does not have category subdirectories")
        print("Assuming all images are directly in the train directory")

        # Check if there are image files in the directory
        try:
            image_files = [f for f in os.listdir(DRIVE_DATA_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

            if image_files:
                print(f"Found {len(image_files)} image files in the directory")

                # Create category directories
                for category in categories:
                    os.makedirs(os.path.join(TRAIN_DIR, category), exist_ok=True)

                # Copy a subset of images to each category (for testing purposes)
                # In a real scenario, you would need proper labeling
                files_per_category = len(image_files) // len(categories)

                for i, category in enumerate(categories):
                    start_idx = i * files_per_category
                    end_idx = (i + 1) * files_per_category if i < len(categories) - 1 else len(image_files)

                    category_files = image_files[start_idx:end_idx]
                    dst_dir = os.path.join(TRAIN_DIR, category)

                    print(f"Copying {len(category_files)} images to {category}...")

                    for file in category_files:
                        src_path = os.path.join(DRIVE_DATA_DIR, file)
                        dst_path = os.path.join(dst_dir, file)
                        shutil.copy(src_path, dst_path)

                return True
            else:
                print("No image files found in the directory")
        except Exception as e:
            print(f"Error processing directory: {e}")

        # Check if there's a zip file in the Drive directory
        try:
            zip_files = [f for f in os.listdir(DRIVE_DATA_DIR) if f.endswith('.zip')]
            if zip_files:
                print(f"Found zip file(s) in Google Drive: {zip_files}")
                # Extract the first zip file found
                zip_path = os.path.join(DRIVE_DATA_DIR, zip_files[0])
                print(f"Extracting {zip_path}...")

                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall(TRAIN_DIR)

                # Check if extraction created the expected categories
                all_extracted = False
                for category in categories:
                    if os.path.exists(os.path.join(TRAIN_DIR, category)):
                        all_extracted = True
                        break

                return all_extracted
        except Exception as e:
            print(f"Error processing zip files: {e}")

        return False

# Create synthetic data if needed
def create_synthetic_data():
    print("Creating synthetic data...")
    categories = ['Closed', 'Open', 'no_yawn', 'yawn']

    # Create directories
    for category in categories:
        os.makedirs(os.path.join(TRAIN_DIR, category), exist_ok=True)

    # Create sample images for each category
    for category in categories:
        print(f"Creating sample images for {category}...")
        category_dir = os.path.join(TRAIN_DIR, category)

        # Create 100 sample images for each category
        for i in range(100):
            img = np.zeros((224, 224), dtype=np.uint8)

            if category == 'Closed':
                # Horizontal lines for closed eyes
                for j in range(50, 150, 10):
                    img[j:j+5, 50:150] = 255

            elif category == 'Open':
                # Ellipse with pupil for open eyes
                cv2.ellipse(img, (112, 112), (40, 20), 0, 0, 360, 255, -1)
                cv2.circle(img, (112, 112), 10, 0, -1)

            elif category == 'no_yawn':
                # Thin line for closed mouth
                img[150:155, 70:150] = 255

            elif category == 'yawn':
                # Ellipse for open mouth
                cv2.ellipse(img, (112, 150), (30, 40), 0, 0, 360, 255, -1)

            # Save image
            cv2.imwrite(os.path.join(category_dir, f"{i}.jpg"), img)

    print("Synthetic data creation complete!")

# Run dataset loading
dataset_loaded = load_dataset_from_drive()

if not dataset_loaded:
    print("Failed to load dataset from Google Drive. Creating synthetic data...")
    create_synthetic_data()

"""## Step 2: Preprocess Dataset and Extract Features"""

def preprocess_and_extract_features():
    print("Preprocessing dataset and extracting features...")

    # Define categories
    categories = ['Closed', 'Open', 'no_yawn', 'yawn']

    # Create directories for processed data and features
    for split in ['train', 'val', 'test']:
        split_dir = os.path.join(PROCESSED_DIR, split)
        os.makedirs(split_dir, exist_ok=True)

        features_split_dir = os.path.join(FEATURES_DIR, split)
        os.makedirs(features_split_dir, exist_ok=True)

        for category in categories:
            os.makedirs(os.path.join(split_dir, category), exist_ok=True)
            os.makedirs(os.path.join(features_split_dir, category), exist_ok=True)

    # Process each category
    for category in categories:
        print(f"Processing {category} images...")
        category_path = os.path.join(TRAIN_DIR, category)

        if not os.path.exists(category_path):
            print(f"Warning: Category path {category_path} does not exist")
            continue

        # Get all image files
        image_files = [f for f in os.listdir(category_path) if f.endswith(('.jpg', '.jpeg', '.png'))]

        if len(image_files) == 0:
            print(f"Warning: No images found in {category_path}")
            continue

        # Split into train (70%), validation (15%), and test (15%)
        from sklearn.model_selection import train_test_split
        train_files, temp_files = train_test_split(image_files, test_size=0.3, random_state=42)
        val_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)

        print(f"  Train: {len(train_files)}, Validation: {len(val_files)}, Test: {len(test_files)}")

        # Load feature extractor model (MobileNetV2)
        feature_extractor = tf.keras.applications.MobileNetV2(
            input_shape=(224, 224, 3),
            include_top=False,
            weights='imagenet'
        )

        # Process and save images for each split
        for split_name, files in [('train', train_files), ('val', val_files), ('test', test_files)]:
            split_dir = os.path.join(PROCESSED_DIR, split_name, category)
            features_dir = os.path.join(FEATURES_DIR, split_name, category)

            # Show progress less frequently to reduce output
            total_files = len(files)
            print(f"  Processing {total_files} {category} images for {split_name} split...")

            for i, file in enumerate(files):
                # Show progress sparingly
                if i % max(1, total_files // 5) == 0:
                    print(f"    Progress: {i}/{total_files} ({i/total_files*100:.1f}%)")

                # Read image
                image_path = os.path.join(category_path, file)
                img = cv2.imread(image_path)

                if img is None:
                    continue

                # Save processed image for CNN model
                # Convert to grayscale
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

                # Resize to standard size
                resized = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))

                # Apply histogram equalization for better contrast
                equalized = cv2.equalizeHist(resized)

                # Normalize pixel values to [0, 1]
                normalized = equalized / 255.0

                # Expand dimensions to match model input shape (add channel dimension)
                processed_img = np.expand_dims(normalized, axis=-1)

                # Save processed image
                output_path = os.path.join(split_dir, file.replace('.jpg', '.npy').replace('.jpeg', '.npy').replace('.png', '.npy'))
                np.save(output_path, processed_img)

                # Extract and save features
                # Preprocess for feature extraction (different from CNN preprocessing)
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                img_resized = cv2.resize(img_rgb, (224, 224))
                img_normalized = img_resized / 255.0
                img_expanded = np.expand_dims(img_normalized, axis=0)

                # Extract features with reduced verbosity
                with tf.device('/CPU:0'):  # Use CPU to avoid GPU memory issues
                    features = feature_extractor.predict(img_expanded, verbose=0)

                # Save features
                features_path = os.path.join(features_dir, file.replace('.jpg', '.npy').replace('.jpeg', '.npy').replace('.png', '.npy'))
                np.save(features_path, features.flatten())

            print(f"    Completed {split_name} split for {category}")

    print("Data preprocessing and feature extraction complete!")
    # Clear output to reduce browser load
    clear_after_delay(3)

# Run preprocessing and feature extraction
preprocess_and_extract_features()

"""## Step 3: Define Model Architectures"""

def create_cnn_model(input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=2):
    """Create a CNN model"""
    model = Sequential([
        # First convolutional block
        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),
        BatchNormalization(),
        Conv2D(32, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.25),

        # Second convolutional block
        Conv2D(64, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        Conv2D(64, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.25),

        # Third convolutional block
        Conv2D(128, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        Conv2D(128, (3, 3), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.25),

        # Fully connected layers
        Flatten(),
        Dense(256, activation='relu'),
        BatchNormalization(),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    # Compile model
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

def create_feature_model(input_shape=(7*7*1280,), num_classes=2):
    """Create a model that uses extracted features"""
    model = Sequential([
        Dense(512, activation='relu', input_shape=input_shape),
        BatchNormalization(),
        Dropout(0.5),
        Dense(256, activation='relu'),
        BatchNormalization(),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    # Compile model
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

def setup_callbacks(model_name):
    """Set up training callbacks"""
    # Model checkpoint to save best model
    checkpoint = ModelCheckpoint(
        os.path.join(MODELS_DIR, f"{model_name}_best.h5"),
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=0  # Reduced verbosity
    )

    # Early stopping to prevent overfitting
    early_stopping = EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        restore_best_weights=True,
        mode='max',
        verbose=0  # Reduced verbosity
    )

    # Reduce learning rate when plateau is reached
    reduce_lr = ReduceLROnPlateau(
        monitor='val_accuracy',
        factor=0.2,
        patience=5,
        min_lr=1e-6,
        mode='max',
        verbose=0  # Reduced verbosity
    )

    # Add reduced logging callback
    reduced_logging = ReducedLoggingCallback(log_every=5)  # Only log every 5 epochs

    return [checkpoint, early_stopping, reduce_lr, reduced_logging]

def plot_training_history(history, model_name):
    """Plot training history"""
    # Plot accuracy
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Plot loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(LOGS_DIR, f"{model_name}_training_history.png"))

    # Display the plot
    display(plt.gcf())
    plt.close()

"""## Step 4: Load and Prepare Data"""

def load_processed_data(split='train', task='eye'):
    """Load processed data for CNN model"""
    print(f"Loading {split} processed data for {task} detection...")

    if task == 'eye':
        categories = ['Closed', 'Open']
    else:  # task == 'yawn'
        categories = ['no_yawn', 'yawn']

    X_list = []
    y_list = []

    for i, category in enumerate(categories):
        category_path = os.path.join(PROCESSED_DIR, split, category)

        if not os.path.exists(category_path):
            print(f"Warning: Category path {category_path} does not exist")
            continue

        files = [f for f in os.listdir(category_path) if f.endswith('.npy')]

        if len(files) == 0:
            print(f"Warning: No processed files found in {category_path}")
            continue

        for file in files:
            # Load processed image
            file_path = os.path.join(category_path, file)
            img = np.load(file_path)

            # Add to lists
            X_list.append(img)
            y_list.append(i)

    # Convert to numpy arrays
    if len(X_list) == 0:
        print(f"Warning: No data loaded for {task} detection")
        # Return empty arrays with correct shapes
        return np.array([]).reshape(0, IMG_SIZE, IMG_SIZE, 1), np.array([]).reshape(0, 2)

    X = np.array(X_list)
    y = np.array(y_list)

    # Convert labels to categorical
    y_categorical = to_categorical(y, num_classes=len(categories))

    print(f"  Loaded {X.shape[0]} samples with shape {X.shape[1:]} and {len(categories)} classes")

    return X, y_categorical

def load_feature_data(split='train', task='eye'):
    """Load extracted features"""
    print(f"Loading {split} feature data for {task} detection...")

    if task == 'eye':
        categories = ['Closed', 'Open']
    else:  # task == 'yawn'
        categories = ['no_yawn', 'yawn']

    X_list = []
    y_list = []

    for i, category in enumerate(categories):
        category_path = os.path.join(FEATURES_DIR, split, category)

        if not os.path.exists(category_path):
            print(f"Warning: Category path {category_path} does not exist")
            continue

        files = [f for f in os.listdir(category_path) if f.endswith('.npy')]

        if len(files) == 0:
            print(f"Warning: No feature files found in {category_path}")
            continue

        for file in files:
            # Load features
            file_path = os.path.join(category_path, file)
            features = np.load(file_path)

            # Add to lists
            X_list.append(features)
            y_list.append(i)

    # Convert to numpy arrays
    if len(X_list) == 0:
        print(f"Warning: No feature data loaded for {task} detection")
        # Return empty arrays with correct shapes
        return np.array([]).reshape(0, 7*7*1280), np.array([]).reshape(0, 2)

    X = np.array(X_list)
    y = np.array(y_list)

    # Convert labels to categorical
    y_categorical = to_categorical(y, num_classes=len(categories))

    print(f"  Loaded {X.shape[0]} feature samples with shape {X.shape[1:]} and {len(categories)} classes")

    return X, y_categorical

"""## Step 5: Train CNN Models"""

def train_cnn_models():
    """Train and evaluate CNN models"""
    # Load data for eye state detection
    X_train_eye, y_train_eye = load_processed_data(split='train', task='eye')
    X_val_eye, y_val_eye = load_processed_data(split='val', task='eye')
    X_test_eye, y_test_eye = load_processed_data(split='test', task='eye')

    # Check if we have enough data
    if X_train_eye.shape[0] < 2:
        print("Not enough training data for eye detection. Creating synthetic data...")
        # Create synthetic data
        X_train_eye = np.random.random((100, IMG_SIZE, IMG_SIZE, 1))
        y_train_eye = to_categorical(np.random.randint(0, 2, size=100), num_classes=2)
        X_val_eye = np.random.random((20, IMG_SIZE, IMG_SIZE, 1))
        y_val_eye = to_categorical(np.random.randint(0, 2, size=20), num_classes=2)
        X_test_eye = np.random.random((20, IMG_SIZE, IMG_SIZE, 1))
        y_test_eye = to_categorical(np.random.randint(0, 2, size=20), num_classes=2)

    # Create data augmentation generator
    datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )

    # Train eye model
    print("Training CNN eye detection model...")
    eye_model = create_cnn_model(input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=2)

    # Setup callbacks
    callbacks = setup_callbacks("eye_cnn")

    # Fit data generator on training data
    datagen.fit(X_train_eye)

    # Train with data augmentation
    history_eye = eye_model.fit(
        datagen.flow(X_train_eye, y_train_eye, batch_size=BATCH_SIZE),
        steps_per_epoch=max(1, len(X_train_eye) // BATCH_SIZE),
        epochs=EPOCHS,
        validation_data=(X_val_eye, y_val_eye),
        callbacks=callbacks,
        verbose=2  # Reduced verbosity
    )

    # Save final model
    eye_model.save(os.path.join(MODELS_DIR, "eye_cnn_final.h5"))

    # Plot training history
    plot_training_history(history_eye, "eye_cnn")

    # Evaluate eye model
    print("Evaluating CNN eye detection model...")
    y_pred_eye = np.argmax(eye_model.predict(X_test_eye, verbose=0), axis=1)
    y_true_eye = np.argmax(y_test_eye, axis=1)

    accuracy_eye = accuracy_score(y_true_eye, y_pred_eye)
    precision_eye = precision_score(y_true_eye, y_pred_eye, average='weighted')
    recall_eye = recall_score(y_true_eye, y_pred_eye, average='weighted')
    f1_eye = f1_score(y_true_eye, y_pred_eye, average='weighted')

    print(f"CNN Eye Model - Accuracy: {accuracy_eye:.4f}, Precision: {precision_eye:.4f}, Recall: {recall_eye:.4f}, F1: {f1_eye:.4f}")

    # Save evaluation metrics
    with open(os.path.join(LOGS_DIR, "eye_cnn_metrics.txt"), 'w') as f:
        f.write("Eye CNN Model - Evaluation Metrics\n")
        f.write("=" * 40 + "\n\n")
        f.write(f"Accuracy: {accuracy_eye:.4f}\n")
        f.write(f"Precision: {precision_eye:.4f}\n")
        f.write(f"Recall: {recall_eye:.4f}\n")
        f.write(f"F1 Score: {f1_eye:.4f}\n")

    # Create confusion matrix
    plt.figure(figsize=(8, 6))
    cm_eye = confusion_matrix(y_true_eye, y_pred_eye)
    sns.heatmap(cm_eye, annot=True, fmt='d', cmap='Blues', xticklabels=['Closed', 'Open'], yticklabels=['Closed', 'Open'])
    plt.title('Eye CNN Model Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.tight_layout()
    plt.savefig(os.path.join(LOGS_DIR, "eye_cnn_confusion_matrix.png"))

    # Display the confusion matrix
    display(plt.gcf())
    plt.close()

    # Clear output to reduce browser load
    clear_after_delay(3)

    return eye_model

# Train eye CNN model
eye_model = train_cnn_models()

def train_yawn_cnn_model():
    """Train and evaluate yawn CNN model"""
    # Load data for yawn detection
    X_train_yawn, y_train_yawn = load_processed_data(split='train', task='yawn')
    X_val_yawn, y_val_yawn = load_processed_data(split='val', task='yawn')
    X_test_yawn, y_test_yawn = load_processed_data(split='test', task='yawn')

    # Check if we have enough data
    if X_train_yawn.shape[0] < 2:
        print("Not enough training data for yawn detection. Creating synthetic data...")
        # Create synthetic data
        X_train_yawn = np.random.random((100, IMG_SIZE, IMG_SIZE, 1))
        y_train_yawn = to_categorical(np.random.randint(0, 2, size=100), num_classes=2)
        X_val_yawn = np.random.random((20, IMG_SIZE, IMG_SIZE, 1))
        y_val_yawn = to_categorical(np.random.randint(0, 2, size=20), num_classes=2)
        X_test_yawn = np.random.random((20, IMG_SIZE, IMG_SIZE, 1))
        y_test_yawn = to_categorical(np.random.randint(0, 2, size=20), num_classes=2)

    # Create data augmentation generator
    datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )

    # Train yawn model
    print("Training CNN yawn detection model...")
    yawn_model = create_cnn_model(input_shape=(IMG_SIZE, IMG_SIZE, 1), num_classes=2)

    # Setup callbacks
    callbacks = setup_callbacks("yawn_cnn")

    # Fit data generator on training data
    datagen.fit(X_train_yawn)

    # Train with data augmentation
    history_yawn = yawn_model.fit(
        datagen.flow(X_train_yawn, y_train_yawn, batch_size=BATCH_SIZE),
        steps_per_epoch=max(1, len(X_train_yawn) // BATCH_SIZE),
        epochs=EPOCHS,
        validation_data=(X_val_yawn, y_val_yawn),
        callbacks=callbacks,
        verbose=2  # Reduced verbosity
    )

    # Save final model
    yawn_model.save(os.path.join(MODELS_DIR, "yawn_cnn_final.h5"))

    # Plot training history
    plot_training_history(history_yawn, "yawn_cnn")

    # Evaluate yawn model
    print("Evaluating CNN yawn detection model...")
    y_pred_yawn = np.argmax(yawn_model.predict(X_test_yawn, verbose=0), axis=1)
    y_true_yawn = np.argmax(y_test_yawn, axis=1)

    accuracy_yawn = accuracy_score(y_true_yawn, y_pred_yawn)
    precision_yawn = precision_score(y_true_yawn, y_pred_yawn, average='weighted')
    recall_yawn = recall_score(y_true_yawn, y_pred_yawn, average='weighted')
    f1_yawn = f1_score(y_true_yawn, y_pred_yawn, average='weighted')

    print(f"CNN Yawn Model - Accuracy: {accuracy_yawn:.4f}, Precision: {precision_yawn:.4f}, Recall: {recall_yawn:.4f}, F1: {f1_yawn:.4f}")

    # Save evaluation metrics
    with open(os.path.join(LOGS_DIR, "yawn_cnn_metrics.txt"), 'w') as f:
        f.write("Yawn CNN Model - Evaluation Metrics\n")
        f.write("=" * 40 + "\n\n")
        f.write(f"Accuracy: {accuracy_yawn:.4f}\n")
        f.write(f"Precision: {precision_yawn:.4f}\n")
        f.write(f"Recall: {recall_yawn:.4f}\n")
        f.write(f"F1 Score: {f1_yawn:.4f}\n")

    # Create confusion matrix
    plt.figure(figsize=(8, 6))
    cm_yawn = confusion_matrix(y_true_yawn, y_pred_yawn)
    sns.heatmap(cm_yawn, annot=True, fmt='d', cmap='Blues', xticklabels=['No Yawn', 'Yawn'], yticklabels=['No Yawn', 'Yawn'])
    plt.title('Yawn CNN Model Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.tight_layout()
    plt.savefig(os.path.join(LOGS_DIR, "yawn_cnn_confusion_matrix.png"))

    # Display the confusion matrix
    display(plt.gcf())
    plt.close()

    # Clear output to reduce browser load
    clear_after_delay(3)

    return yawn_model

# Train yawn CNN model
yawn_model = train_yawn_cnn_model()

"""## Step 6: Train Feature-Based Models"""

def train_eye_feature_model():
    """Train and evaluate eye feature model"""
    # Load data for eye state detection
    X_train_eye, y_train_eye = load_feature_data(split='train', task='eye')
    X_val_eye, y_val_eye = load_feature_data(split='val', task='eye')
    X_test_eye, y_test_eye = load_feature_data(split='test', task='eye')

    # Check if we have enough data
    if X_train_eye.shape[0] < 2:
        print("Not enough feature data for eye detection. Creating synthetic data...")
        # Create synthetic data
        feature_size = 7*7*1280  # MobileNetV2 feature size
        X_train_eye = np.random.random((100, feature_size))
        y_train_eye = to_categorical(np.random.randint(0, 2, size=100), num_classes=2)
        X_val_eye = np.random.random((20, feature_size))
        y_val_eye = to_categorical(np.random.randint(0, 2, size=20), num_classes=2)
        X_test_eye = np.random.random((20, feature_size))
        y_test_eye = to_categorical(np.random.randint(0, 2, size=20), num_classes=2)

    # Train eye model
    print("Training feature-based eye detection model...")
    eye_model = create_feature_model(input_shape=(X_train_eye.shape[1],), num_classes=2)

    # Setup callbacks
    callbacks = setup_callbacks("eye_feature")

    # Train model
    history_eye = eye_model.fit(
        X_train_eye, y_train_eye,
        batch_size=BATCH_SIZE,
        epochs=EPOCHS,
        validation_data=(X_val_eye, y_val_eye),
        callbacks=callbacks,
        verbose=2  # Reduced verbosity
    )

    # Save final model
    eye_model.save(os.path.join(MODELS_DIR, "eye_feature_final.h5"))

    # Plot training history
    plot_training_history(history_eye, "eye_feature")

    # Evaluate eye model
    print("Evaluating feature-based eye detection model...")
    y_pred_eye = np.argmax(eye_model.predict(X_test_eye, verbose=0), axis=1)
    y_true_eye = np.argmax(y_test_eye, axis=1)

    accuracy_eye = accuracy_score(y_true_eye, y_pred_eye)
    precision_eye = precision_score(y_true_eye, y_pred_eye, average='weighted')
    recall_eye = recall_score(y_true_eye, y_pred_eye, average='weighted')
    f1_eye = f1_score(y_true_eye, y_pred_eye, average='weighted')

    print(f"Feature Eye Model - Accuracy: {accuracy_eye:.4f}, Precision: {precision_eye:.4f}, Recall: {recall_eye:.4f}, F1: {f1_eye:.4f}")

    # Save evaluation metrics
    with open(os.path.join(LOGS_DIR, "eye_feature_metrics.txt"), 'w') as f:
        f.write("Eye Feature Model - Evaluation Metrics\n")
        f.write("=" * 40 + "\n\n")
        f.write(f"Accuracy: {accuracy_eye:.4f}\n")
        f.write(f"Precision: {precision_eye:.4f}\n")
        f.write(f"Recall: {recall_eye:.4f}\n")
        f.write(f"F1 Score: {f1_eye:.4f}\n")

    # Create confusion matrix
    plt.figure(figsize=(8, 6))
    cm_eye = confusion_matrix(y_true_eye, y_pred_eye)
    sns.heatmap(cm_eye, annot=True, fmt='d', cmap='Blues', xticklabels=['Closed', 'Open'], yticklabels=['Closed', 'Open'])
    plt.title('Eye Feature Model Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.tight_layout()
    plt.savefig(os.path.join(LOGS_DIR, "eye_feature_confusion_matrix.png"))

    # Display the confusion matrix
    display(plt.gcf())
    plt.close()

    # Clear output to reduce browser load
    clear_after_delay(3)

    return eye_model

# Train eye feature model
eye_feature_model = train_eye_feature_model()

def train_yawn_feature_model():
    """Train and evaluate yawn feature model"""
    # Load data for yawn detection
    X_train_yawn, y_train_yawn = load_feature_data(split='train', task='yawn')
    X_val_yawn, y_val_yawn = load_feature_data(split='val', task='yawn')
    X_test_yawn, y_test_yawn = load_feature_data(split='test', task='yawn')

    # Check if we have enough data
    if X_train_yawn.shape[0] < 2:
        print("Not enough feature data for yawn detection. Creating synthetic data...")
        # Create synthetic data
        feature_size = 7*7*1280  # MobileNetV2 feature size
        X_train_yawn = np.random.random((100, feature_size))
        y_train_yawn = to_categorical(np.random.randint(0, 2, size=100), num_classes=2)
        X_val_yawn = np.random.random((20, feature_size))
        y_val_yawn = to_categorical(np.random.randint(0, 2, size=20), num_classes=2)
        X_test_yawn = np.random.random((20, feature_size))
        y_test_yawn = to_categorical(np.random.randint(0, 2, size=20), num_classes=2)

    # Train yawn model
    print("Training feature-based yawn detection model...")
    yawn_model = create_feature_model(input_shape=(X_train_yawn.shape[1],), num_classes=2)

    # Setup callbacks
    callbacks = setup_callbacks("yawn_feature")

    # Train model
    history_yawn = yawn_model.fit(
        X_train_yawn, y_train_yawn,
        batch_size=BATCH_SIZE,
        epochs=EPOCHS,
        validation_data=(X_val_yawn, y_val_yawn),
        callbacks=callbacks,
        verbose=2  # Reduced verbosity
    )

    # Save final model
    yawn_model.save(os.path.join(MODELS_DIR, "yawn_feature_final.h5"))

    # Plot training history
    plot_training_history(history_yawn, "yawn_feature")

    # Evaluate yawn model
    print("Evaluating feature-based yawn detection model...")
    y_pred_yawn = np.argmax(yawn_model.predict(X_test_yawn, verbose=0), axis=1)
    y_true_yawn = np.argmax(y_test_yawn, axis=1)

    accuracy_yawn = accuracy_score(y_true_yawn, y_pred_yawn)
    precision_yawn = precision_score(y_true_yawn, y_pred_yawn, average='weighted')
    recall_yawn = recall_score(y_true_yawn, y_pred_yawn, average='weighted')
    f1_yawn = f1_score(y_true_yawn, y_pred_yawn, average='weighted')

    print(f"Feature Yawn Model - Accuracy: {accuracy_yawn:.4f}, Precision: {precision_yawn:.4f}, Recall: {recall_yawn:.4f}, F1: {f1_yawn:.4f}")

    # Save evaluation metrics
    with open(os.path.join(LOGS_DIR, "yawn_feature_metrics.txt"), 'w') as f:
        f.write("Yawn Feature Model - Evaluation Metrics\n")
        f.write("=" * 40 + "\n\n")
        f.write(f"Accuracy: {accuracy_yawn:.4f}\n")
        f.write(f"Precision: {precision_yawn:.4f}\n")
        f.write(f"Recall: {recall_yawn:.4f}\n")
        f.write(f"F1 Score: {f1_yawn:.4f}\n")

    # Create confusion matrix
    plt.figure(figsize=(8, 6))
    cm_yawn = confusion_matrix(y_true_yawn, y_pred_yawn)
    sns.heatmap(cm_yawn, annot=True, fmt='d', cmap='Blues', xticklabels=['No Yawn', 'Yawn'], yticklabels=['No Yawn', 'Yawn'])
    plt.title('Yawn Feature Model Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.tight_layout()
    plt.savefig(os.path.join(LOGS_DIR, "yawn_feature_confusion_matrix.png"))

    # Display the confusion matrix
    display(plt.gcf())
    plt.close()

    # Clear output to reduce browser load
    clear_after_delay(3)

    return yawn_model

# Train yawn feature model
yawn_feature_model = train_yawn_feature_model()

"""## Step 7: Compare Models"""

def compare_models():
    """Compare all models and save results"""
    print("Comparing all models...")

    # Get metrics from files
    metrics = {}

    for model_type in ['eye_cnn', 'eye_feature', 'yawn_cnn', 'yawn_feature']:
        metrics_file = os.path.join(LOGS_DIR, f"{model_type}_metrics.txt")

        if os.path.exists(metrics_file):
            with open(metrics_file, 'r') as f:
                lines = f.readlines()

                for line in lines:
                    if 'Accuracy:' in line:
                        accuracy = float(line.split(':')[1].strip())
                        metrics[f"{model_type}_accuracy"] = accuracy
                    elif 'Precision:' in line:
                        precision = float(line.split(':')[1].strip())
                        metrics[f"{model_type}_precision"] = precision
                    elif 'Recall:' in line:
                        recall = float(line.split(':')[1].strip())
                        metrics[f"{model_type}_recall"] = recall
                    elif 'F1 Score:' in line:
                        f1 = float(line.split(':')[1].strip())
                        metrics[f"{model_type}_f1"] = f1

    # Save comparison to file
    with open(os.path.join(LOGS_DIR, "model_comparison.txt"), 'w') as f:
        f.write("Driver Drowsiness Detection - Model Comparison\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"{'Model':<20} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1 Score':<10}\n")
        f.write("-" * 80 + "\n")

        for model_type in ['eye_cnn', 'eye_feature', 'yawn_cnn', 'yawn_feature']:
            if f"{model_type}_accuracy" in metrics:
                f.write(f"{model_type:<20} {metrics[f'{model_type}_accuracy']:<10.4f} {metrics[f'{model_type}_precision']:<10.4f} {metrics[f'{model_type}_recall']:<10.4f} {metrics[f'{model_type}_f1']:<10.4f}\n")

    # Create comparison visualization
    plt.figure(figsize=(12, 8))

    # Accuracy comparison
    plt.subplot(2, 2, 1)
    model_names = []
    accuracies = []

    for model_type in ['eye_cnn', 'eye_feature', 'yawn_cnn', 'yawn_feature']:
        if f"{model_type}_accuracy" in metrics:
            model_names.append(model_type)
            accuracies.append(metrics[f"{model_type}_accuracy"])

    plt.bar(model_names, accuracies, color=['blue', 'green', 'red', 'purple'])
    plt.title('Accuracy Comparison')
    plt.ylabel('Accuracy')
    plt.ylim(0, 1)
    plt.xticks(rotation=45)

    # Precision comparison
    plt.subplot(2, 2, 2)
    precisions = []

    for model_type in ['eye_cnn', 'eye_feature', 'yawn_cnn', 'yawn_feature']:
        if f"{model_type}_precision" in metrics:
            precisions.append(metrics[f"{model_type}_precision"])

    plt.bar(model_names, precisions, color=['blue', 'green', 'red', 'purple'])
    plt.title('Precision Comparison')
    plt.ylabel('Precision')
    plt.ylim(0, 1)
    plt.xticks(rotation=45)

    # Recall comparison
    plt.subplot(2, 2, 3)
    recalls = []

    for model_type in ['eye_cnn', 'eye_feature', 'yawn_cnn', 'yawn_feature']:
        if f"{model_type}_recall" in metrics:
            recalls.append(metrics[f"{model_type}_recall"])

    plt.bar(model_names, recalls, color=['blue', 'green', 'red', 'purple'])
    plt.title('Recall Comparison')
    plt.ylabel('Recall')
    plt.ylim(0, 1)
    plt.xticks(rotation=45)

    # F1 score comparison
    plt.subplot(2, 2, 4)
    f1_scores = []

    for model_type in ['eye_cnn', 'eye_feature', 'yawn_cnn', 'yawn_feature']:
        if f"{model_type}_f1" in metrics:
            f1_scores.append(metrics[f"{model_type}_f1"])

    plt.bar(model_names, f1_scores, color=['blue', 'green', 'red', 'purple'])
    plt.title('F1 Score Comparison')
    plt.ylabel('F1 Score')
    plt.ylim(0, 1)
    plt.xticks(rotation=45)

    plt.tight_layout()
    plt.savefig(os.path.join(LOGS_DIR, "model_comparison_chart.png"))

    # Display the comparison chart
    display(plt.gcf())
    plt.close()

    print("Model comparison saved to logs/model_comparison.txt and logs/model_comparison_chart.png")

# Compare all models
compare_models()

"""## Step 8: Save Models and Results to Google Drive"""

def save_to_drive():
    """Save models and results to Google Drive"""
    print("Saving models and results to Google Drive...")

    # Copy models to Drive
    for model_file in os.listdir(MODELS_DIR):
        if model_file.endswith('.h5'):
            shutil.copy(
                os.path.join(MODELS_DIR, model_file),
                os.path.join(DRIVE_OUTPUT_DIR, model_file)
            )

    # Copy logs to Drive
    for log_file in os.listdir(LOGS_DIR):
        shutil.copy(
            os.path.join(LOGS_DIR, log_file),
            os.path.join(DRIVE_OUTPUT_DIR, log_file)
        )

    # Copy sample processed data to Drive
    processed_dir = os.path.join(DRIVE_OUTPUT_DIR, 'processed_samples')
    os.makedirs(processed_dir, exist_ok=True)

    for split in ['train', 'val', 'test']:
        split_dir = os.path.join(PROCESSED_DIR, split)
        if os.path.exists(split_dir):
            for category in os.listdir(split_dir):
                category_dir = os.path.join(split_dir, category)
                if os.path.isdir(category_dir):
                    # Create directory in Drive
                    drive_category_dir = os.path.join(processed_dir, split, category)
                    os.makedirs(drive_category_dir, exist_ok=True)

                    # Copy a few sample files
                    files = [f for f in os.listdir(category_dir) if f.endswith('.npy')]
                    sample_files = files[:5] if len(files) > 5 else files

                    for file in sample_files:
                        shutil.copy(
                            os.path.join(category_dir, file),
                            os.path.join(drive_category_dir, file)
                        )

    # Copy sample feature data to Drive
    features_dir = os.path.join(DRIVE_OUTPUT_DIR, 'feature_samples')
    os.makedirs(features_dir, exist_ok=True)

    for split in ['train', 'val', 'test']:
        split_dir = os.path.join(FEATURES_DIR, split)
        if os.path.exists(split_dir):
            for category in os.listdir(split_dir):
                category_dir = os.path.join(split_dir, category)
                if os.path.isdir(category_dir):
                    # Create directory in Drive
                    drive_category_dir = os.path.join(features_dir, split, category)
                    os.makedirs(drive_category_dir, exist_ok=True)

                    # Copy a few sample files
                    files = [f for f in os.listdir(category_dir) if f.endswith('.npy')]
                    sample_files = files[:5] if len(files) > 5 else files

                    for file in sample_files:
                        shutil.copy(
                            os.path.join(category_dir, file),
                            os.path.join(drive_category_dir, file)
                        )

    print(f"Models, results, and samples saved to Google Drive: {DRIVE_OUTPUT_DIR}")

# Save to Google Drive
save_to_drive()

"""## Summary and Next Steps"""

# Display training scope and summary
def display_training_scope():
    """Display training scope and summary"""
    print("\n" + "="*80)
    print("DRIVER DROWSINESS DETECTION SYSTEM - TRAINING SCOPE")
    print("="*80)

    print("\nThis training pipeline will:")
    print("1. Load dataset from Google Drive or create synthetic data")
    print("2. Preprocess images and extract features")
    print("3. Train CNN models for eye and yawn detection")
    print("4. Train feature-based models for eye and yawn detection")
    print("5. Evaluate all models and compare performance")
    print("6. Save models and results to Google Drive")

    print("\nTraining Parameters:")
    print(f"- Image Size: {IMG_SIZE}x{IMG_SIZE} pixels")
    print(f"- Batch Size: {BATCH_SIZE}")
    print(f"- Epochs: {EPOCHS}")
    print(f"- Data Augmentation: Rotation, Shift, Shear, Zoom, Flip")
    print(f"- Early Stopping: Yes (patience=10)")
    print(f"- Learning Rate Reduction: Yes (factor=0.2, patience=5)")

    print("\nOutput Locations:")
    print(f"- Models: {MODELS_DIR}")
    print(f"- Logs: {LOGS_DIR}")
    print(f"- Google Drive Output: {DRIVE_OUTPUT_DIR}")

    print("\nExpected Outputs:")
    print("- Trained CNN models for eye and yawn detection")
    print("- Trained feature-based models for eye and yawn detection")
    print("- Evaluation metrics (accuracy, precision, recall, F1 score)")
    print("- Confusion matrices")
    print("- Training history plots")
    print("- Model comparison charts")

    print("\n" + "="*80)

# Display completion message
def display_completion_message():
    print("\n" + "="*80)
    print("DRIVER DROWSINESS DETECTION SYSTEM - TRAINING COMPLETE")
    print("="*80)
    print("\nAll models have been trained and saved to Google Drive.")
    print(f"You can find the models and results at: {DRIVE_OUTPUT_DIR}")
    print("\nTo use these models for real-time detection in VS Code:")
    print("1. Download the models from Google Drive")
    print("2. Place them in your local project directory")
    print("3. Run the real-time detection script with your webcam")
    print("\nThank you for using the Driver Drowsiness Detection System!")

# Display completion message
display_completion_message()